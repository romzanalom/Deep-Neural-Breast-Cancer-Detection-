{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9073122,"sourceType":"datasetVersion","datasetId":5472989},{"sourceId":2021025,"sourceType":"datasetVersion","datasetId":1209633}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 3\nepochs = 20\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Create lists to hold the test loss and accuracy\ntest_loss = []\ntest_accuracy = []\n\n# Custom callback to record test loss and accuracy after each epoch\nclass TestCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        loss, acc = model.evaluate(test_generator, verbose=0)\n        test_loss.append(loss)\n        test_accuracy.append(acc)\n        print(f'Test loss: {loss:.4f} - Test accuracy: {acc:.4f}')\n\n# Train the model with the custom callback\nhistory = model.fit(train_generator_balanced, \n                    epochs=epochs, \n                    validation_data=validation_generator_balanced, \n                    class_weight=class_weights_balanced,\n                    callbacks=[TestCallback()])\n\n# Final evaluation on the test set\nloss, accuracy = model.evaluate(test_generator)\nprint('Final Test Loss:', loss)\nprint(f'Final Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:04:16.612558Z","iopub.execute_input":"2024-11-11T03:04:16.613238Z","iopub.status.idle":"2024-11-11T03:11:57.627124Z","shell.execute_reply.started":"2024-11-11T03:04:16.613197Z","shell.execute_reply":"2024-11-11T03:11:57.626130Z"}},"outputs":[{"name":"stdout","text":"Found 1106 images belonging to 3 classes.\nFound 472 images belonging to 3 classes.\nFound 1578 images belonging to 3 classes.\nEpoch 1/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.3664 - loss: 12.4762Test loss: 0.8762 - Test accuracy: 0.7383\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 639ms/step - accuracy: 0.3679 - loss: 12.2995 - val_accuracy: 0.6377 - val_loss: 0.9796\nEpoch 2/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.7961 - loss: 0.8400Test loss: 0.6209 - Test accuracy: 0.8093\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 606ms/step - accuracy: 0.7956 - loss: 0.8392 - val_accuracy: 0.6038 - val_loss: 0.9016\nEpoch 3/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8862 - loss: 0.5024Test loss: 0.4458 - Test accuracy: 0.8580\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 602ms/step - accuracy: 0.8862 - loss: 0.5011 - val_accuracy: 0.5996 - val_loss: 1.0328\nEpoch 4/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9600 - loss: 0.1548Test loss: 0.4496 - Test accuracy: 0.8745\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 599ms/step - accuracy: 0.9600 - loss: 0.1543 - val_accuracy: 0.6250 - val_loss: 1.3451\nEpoch 5/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9947 - loss: 0.0331Test loss: 0.4154 - Test accuracy: 0.8929\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 603ms/step - accuracy: 0.9947 - loss: 0.0331 - val_accuracy: 0.6441 - val_loss: 1.3707\nEpoch 6/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.0049Test loss: 0.4759 - Test accuracy: 0.8954\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 607ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.6504 - val_loss: 1.5866\nEpoch 7/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 0.0015Test loss: 0.4934 - Test accuracy: 0.8929\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6419 - val_loss: 1.6462\nEpoch 8/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.0024Test loss: 0.5003 - Test accuracy: 0.8967\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 604ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6547 - val_loss: 1.6697\nEpoch 9/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0014Test loss: 0.5107 - Test accuracy: 0.8935\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 610ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.6441 - val_loss: 1.7061\nEpoch 10/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 3.4113e-04Test loss: 0.5591 - Test accuracy: 0.8885\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 606ms/step - accuracy: 1.0000 - loss: 3.4152e-04 - val_accuracy: 0.6271 - val_loss: 1.8684\nEpoch 11/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 2.6982e-04Test loss: 0.5649 - Test accuracy: 0.8891\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 598ms/step - accuracy: 1.0000 - loss: 2.6946e-04 - val_accuracy: 0.6292 - val_loss: 1.8881\nEpoch 12/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 1.9605e-04Test loss: 0.5748 - Test accuracy: 0.8897\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 589ms/step - accuracy: 1.0000 - loss: 1.9606e-04 - val_accuracy: 0.6314 - val_loss: 1.9212\nEpoch 13/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 1.6776e-04Test loss: 0.5792 - Test accuracy: 0.8891\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 1.6750e-04 - val_accuracy: 0.6292 - val_loss: 1.9360\nEpoch 14/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 1.3952e-04Test loss: 0.5950 - Test accuracy: 0.8891\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 603ms/step - accuracy: 1.0000 - loss: 1.3937e-04 - val_accuracy: 0.6292 - val_loss: 1.9891\nEpoch 15/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 1.1667e-04Test loss: 0.5931 - Test accuracy: 0.8891\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 596ms/step - accuracy: 1.0000 - loss: 1.1664e-04 - val_accuracy: 0.6292 - val_loss: 1.9827\nEpoch 16/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 9.4758e-05Test loss: 0.6068 - Test accuracy: 0.8885\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 600ms/step - accuracy: 1.0000 - loss: 9.4841e-05 - val_accuracy: 0.6271 - val_loss: 2.0286\nEpoch 17/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 8.4953e-05Test loss: 0.6074 - Test accuracy: 0.8891\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 601ms/step - accuracy: 1.0000 - loss: 8.4992e-05 - val_accuracy: 0.6292 - val_loss: 2.0305\nEpoch 18/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 7.8272e-05Test loss: 0.6167 - Test accuracy: 0.8885\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 600ms/step - accuracy: 1.0000 - loss: 7.8210e-05 - val_accuracy: 0.6271 - val_loss: 2.0616\nEpoch 19/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 7.2481e-05Test loss: 0.6256 - Test accuracy: 0.8878\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 612ms/step - accuracy: 1.0000 - loss: 7.2366e-05 - val_accuracy: 0.6250 - val_loss: 2.0915\nEpoch 20/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 6.3336e-05Test loss: 0.6275 - Test accuracy: 0.8885\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 1.0000 - loss: 6.3267e-05 - val_accuracy: 0.6271 - val_loss: 2.0978\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - accuracy: 0.8557 - loss: 0.6776\nFinal Test Loss: 0.6275199055671692\nFinal Test Accuracy: 88.85%\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# 2 Block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 3\nepochs = 20\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Create lists to hold the test loss and accuracy\ntest_loss = []\ntest_accuracy = []\n\n# Custom callback to record test loss and accuracy after each epoch\nclass TestCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        loss, acc = model.evaluate(test_generator, verbose=0)\n        test_loss.append(loss)\n        test_accuracy.append(acc)\n        print(f'Test loss: {loss:.4f} - Test accuracy: {acc:.4f}')\n\n# Train the model with the custom callback\nhistory = model.fit(train_generator_balanced, \n                    epochs=epochs, \n                    validation_data=validation_generator_balanced, \n                    class_weight=class_weights_balanced,\n                    callbacks=[TestCallback()])\n\n# Final evaluation on the test set\nloss, accuracy = model.evaluate(test_generator)\nprint('Final Test Loss:', loss)\nprint(f'Final Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:11:57.629346Z","iopub.execute_input":"2024-11-11T03:11:57.629805Z","iopub.status.idle":"2024-11-11T03:20:02.702027Z","shell.execute_reply.started":"2024-11-11T03:11:57.629756Z","shell.execute_reply":"2024-11-11T03:20:02.701093Z"}},"outputs":[{"name":"stdout","text":"Found 1106 images belonging to 3 classes.\nFound 472 images belonging to 3 classes.\nFound 1578 images belonging to 3 classes.\nEpoch 1/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.3805 - loss: 5.2514Test loss: 0.9419 - Test accuracy: 0.5900\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 773ms/step - accuracy: 0.3809 - loss: 5.1796 - val_accuracy: 0.5530 - val_loss: 0.9771\nEpoch 2/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6514 - loss: 0.8017Test loss: 0.6090 - Test accuracy: 0.7687\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 600ms/step - accuracy: 0.6519 - loss: 0.8005 - val_accuracy: 0.6314 - val_loss: 0.8787\nEpoch 3/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8450 - loss: 0.4341Test loss: 0.4630 - Test accuracy: 0.8454\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 0.8450 - loss: 0.4336 - val_accuracy: 0.6653 - val_loss: 1.0414\nEpoch 4/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9427 - loss: 0.1901Test loss: 0.4362 - Test accuracy: 0.8821\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 0.9428 - loss: 0.1892 - val_accuracy: 0.6547 - val_loss: 1.2992\nEpoch 5/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9771 - loss: 0.0604Test loss: 0.4530 - Test accuracy: 0.8948\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 599ms/step - accuracy: 0.9772 - loss: 0.0601 - val_accuracy: 0.6653 - val_loss: 1.4180\nEpoch 6/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9984 - loss: 0.0200Test loss: 0.5145 - Test accuracy: 0.9100\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 606ms/step - accuracy: 0.9983 - loss: 0.0199 - val_accuracy: 0.7055 - val_loss: 1.6943\nEpoch 7/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9987 - loss: 0.0071Test loss: 0.5402 - Test accuracy: 0.9043\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 0.6843 - val_loss: 1.7921\nEpoch 8/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9965 - loss: 0.0095Test loss: 0.6679 - Test accuracy: 0.9081\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 603ms/step - accuracy: 0.9964 - loss: 0.0096 - val_accuracy: 0.6970 - val_loss: 2.2160\nEpoch 9/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9975 - loss: 0.0081Test loss: 0.5976 - Test accuracy: 0.9081\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 0.9975 - loss: 0.0081 - val_accuracy: 0.6928 - val_loss: 1.9898\nEpoch 10/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9995 - loss: 0.0030Test loss: 0.5801 - Test accuracy: 0.9068\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 588ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.6907 - val_loss: 1.9272\nEpoch 11/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9998 - loss: 0.0015Test loss: 0.6311 - Test accuracy: 0.9106\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 600ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.7013 - val_loss: 2.1072\nEpoch 12/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0016Test loss: 0.6391 - Test accuracy: 0.9094\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 604ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6970 - val_loss: 2.1346\nEpoch 13/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.0012Test loss: 0.5784 - Test accuracy: 0.9106\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 603ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.7034 - val_loss: 1.9263\nEpoch 14/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 8.7914e-04Test loss: 0.6603 - Test accuracy: 0.9106\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 592ms/step - accuracy: 1.0000 - loss: 8.7453e-04 - val_accuracy: 0.7013 - val_loss: 2.2068\nEpoch 15/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 1.9026e-04Test loss: 0.6660 - Test accuracy: 0.9087\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 1.9020e-04 - val_accuracy: 0.6949 - val_loss: 2.2262\nEpoch 16/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 1.3835e-04Test loss: 0.6774 - Test accuracy: 0.9081\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 608ms/step - accuracy: 1.0000 - loss: 1.3808e-04 - val_accuracy: 0.6928 - val_loss: 2.2643\nEpoch 17/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 1.0593e-04Test loss: 0.6911 - Test accuracy: 0.9075\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 598ms/step - accuracy: 1.0000 - loss: 1.0598e-04 - val_accuracy: 0.6907 - val_loss: 2.3102\nEpoch 18/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 9.2845e-05Test loss: 0.6973 - Test accuracy: 0.9081\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 634ms/step - accuracy: 1.0000 - loss: 9.2808e-05 - val_accuracy: 0.6928 - val_loss: 2.3310\nEpoch 19/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 8.7283e-05Test loss: 0.7071 - Test accuracy: 0.9081\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 584ms/step - accuracy: 1.0000 - loss: 8.7196e-05 - val_accuracy: 0.6928 - val_loss: 2.3639\nEpoch 20/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 8.0677e-05Test loss: 0.7129 - Test accuracy: 0.9081\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 584ms/step - accuracy: 1.0000 - loss: 8.0479e-05 - val_accuracy: 0.6928 - val_loss: 2.3833\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - accuracy: 0.8873 - loss: 0.7276\nFinal Test Loss: 0.7129229307174683\nFinal Test Accuracy: 90.81%\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 3 Block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 3\nepochs = 20\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Create lists to hold the test loss and accuracy\ntest_loss = []\ntest_accuracy = []\n\n# Custom callback to record test loss and accuracy after each epoch\nclass TestCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        loss, acc = model.evaluate(test_generator, verbose=0)\n        test_loss.append(loss)\n        test_accuracy.append(acc)\n        print(f'Test loss: {loss:.4f} - Test accuracy: {acc:.4f}')\n\n# Train the model with the custom callback\nhistory = model.fit(train_generator_balanced, \n                    epochs=epochs, \n                    validation_data=validation_generator_balanced, \n                    class_weight=class_weights_balanced,\n                    callbacks=[TestCallback()])\n\n# Final evaluation on the test set\nloss, accuracy = model.evaluate(test_generator)\nprint('Final Test Loss:', loss)\nprint(f'Final Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:20:02.703791Z","iopub.execute_input":"2024-11-11T03:20:02.704444Z","iopub.status.idle":"2024-11-11T03:27:44.945542Z","shell.execute_reply.started":"2024-11-11T03:20:02.704396Z","shell.execute_reply":"2024-11-11T03:27:44.944543Z"}},"outputs":[{"name":"stdout","text":"Found 1106 images belonging to 3 classes.\nFound 472 images belonging to 3 classes.\nFound 1578 images belonging to 3 classes.\nEpoch 1/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.4383 - loss: 1.5413Test loss: 0.8363 - Test accuracy: 0.6781\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 794ms/step - accuracy: 0.4398 - loss: 1.5314 - val_accuracy: 0.6398 - val_loss: 0.8910\nEpoch 2/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6458 - loss: 0.8551Test loss: 0.6639 - Test accuracy: 0.7072\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 598ms/step - accuracy: 0.6459 - loss: 0.8548 - val_accuracy: 0.6271 - val_loss: 0.7979\nEpoch 3/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7434 - loss: 0.5775Test loss: 0.5163 - Test accuracy: 0.8042\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 596ms/step - accuracy: 0.7436 - loss: 0.5769 - val_accuracy: 0.6864 - val_loss: 0.8697\nEpoch 4/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8191 - loss: 0.4411Test loss: 0.6079 - Test accuracy: 0.7313\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 594ms/step - accuracy: 0.8184 - loss: 0.4419 - val_accuracy: 0.6017 - val_loss: 0.9849\nEpoch 5/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8439 - loss: 0.3377Test loss: 0.5809 - Test accuracy: 0.8308\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 605ms/step - accuracy: 0.8441 - loss: 0.3373 - val_accuracy: 0.6674 - val_loss: 1.3850\nEpoch 6/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9303 - loss: 0.1733Test loss: 0.5299 - Test accuracy: 0.8809\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 598ms/step - accuracy: 0.9302 - loss: 0.1736 - val_accuracy: 0.7055 - val_loss: 1.4734\nEpoch 7/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9429 - loss: 0.1139Test loss: 0.6334 - Test accuracy: 0.8973\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 600ms/step - accuracy: 0.9433 - loss: 0.1134 - val_accuracy: 0.7140 - val_loss: 1.9320\nEpoch 8/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9788 - loss: 0.0729Test loss: 0.5594 - Test accuracy: 0.9094\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 0.9785 - loss: 0.0732 - val_accuracy: 0.7309 - val_loss: 1.7409\nEpoch 9/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9794 - loss: 0.0587Test loss: 0.5987 - Test accuracy: 0.9163\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 0.9793 - loss: 0.0588 - val_accuracy: 0.7267 - val_loss: 1.9544\nEpoch 10/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9866 - loss: 0.0457Test loss: 0.5936 - Test accuracy: 0.9056\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 587ms/step - accuracy: 0.9865 - loss: 0.0457 - val_accuracy: 0.7076 - val_loss: 1.8976\nEpoch 11/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9925 - loss: 0.0187Test loss: 0.6277 - Test accuracy: 0.9189\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 594ms/step - accuracy: 0.9926 - loss: 0.0187 - val_accuracy: 0.7373 - val_loss: 2.0649\nEpoch 12/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9910 - loss: 0.0249Test loss: 0.6606 - Test accuracy: 0.9157\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 581ms/step - accuracy: 0.9912 - loss: 0.0244 - val_accuracy: 0.7267 - val_loss: 2.1686\nEpoch 13/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9983 - loss: 0.0062Test loss: 0.7241 - Test accuracy: 0.9125\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 599ms/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 0.7203 - val_loss: 2.3671\nEpoch 14/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9929 - loss: 0.0166Test loss: 0.7045 - Test accuracy: 0.9125\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 590ms/step - accuracy: 0.9930 - loss: 0.0165 - val_accuracy: 0.7161 - val_loss: 2.3332\nEpoch 15/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9980 - loss: 0.0057Test loss: 0.6423 - Test accuracy: 0.9144\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 587ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.7203 - val_loss: 2.1239\nEpoch 16/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9956 - loss: 0.0092Test loss: 0.6321 - Test accuracy: 0.9144\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 602ms/step - accuracy: 0.9956 - loss: 0.0093 - val_accuracy: 0.7203 - val_loss: 2.0950\nEpoch 17/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9961 - loss: 0.0063Test loss: 0.7608 - Test accuracy: 0.9157\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 591ms/step - accuracy: 0.9962 - loss: 0.0062 - val_accuracy: 0.7225 - val_loss: 2.5370\nEpoch 18/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9955 - loss: 0.0042Test loss: 0.7758 - Test accuracy: 0.9151\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 592ms/step - accuracy: 0.9956 - loss: 0.0042 - val_accuracy: 0.7203 - val_loss: 2.5792\nEpoch 19/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9986 - loss: 0.0046Test loss: 0.8062 - Test accuracy: 0.9208\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 609ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.7373 - val_loss: 2.6909\nEpoch 20/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9973 - loss: 0.0061Test loss: 0.8080 - Test accuracy: 0.9163\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 600ms/step - accuracy: 0.9973 - loss: 0.0061 - val_accuracy: 0.7225 - val_loss: 2.6971\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.8990 - loss: 0.8090\nFinal Test Loss: 0.8080031871795654\nFinal Test Accuracy: 91.63%\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# 4 Block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 3\nepochs = 20\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Create lists to hold the test loss and accuracy\ntest_loss = []\ntest_accuracy = []\n\n# Custom callback to record test loss and accuracy after each epoch\nclass TestCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        loss, acc = model.evaluate(test_generator, verbose=0)\n        test_loss.append(loss)\n        test_accuracy.append(acc)\n        print(f'Test loss: {loss:.4f} - Test accuracy: {acc:.4f}')\n\n# Train the model with the custom callback\nhistory = model.fit(train_generator_balanced, \n                    epochs=epochs, \n                    validation_data=validation_generator_balanced, \n                    class_weight=class_weights_balanced,\n                    callbacks=[TestCallback()])\n\n# Final evaluation on the test set\nloss, accuracy = model.evaluate(test_generator)\nprint('Final Test Loss:', loss)\nprint(f'Final Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:27:44.947707Z","iopub.execute_input":"2024-11-11T03:27:44.948028Z","iopub.status.idle":"2024-11-11T03:35:26.967671Z","shell.execute_reply.started":"2024-11-11T03:27:44.947995Z","shell.execute_reply":"2024-11-11T03:35:26.966722Z"}},"outputs":[{"name":"stdout","text":"Found 1106 images belonging to 3 classes.\nFound 472 images belonging to 3 classes.\nFound 1578 images belonging to 3 classes.\nEpoch 1/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.4185 - loss: 1.2425Test loss: 0.7968 - Test accuracy: 0.6388\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 731ms/step - accuracy: 0.4201 - loss: 1.2363 - val_accuracy: 0.6292 - val_loss: 0.8260\nEpoch 2/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6502 - loss: 0.7537Test loss: 0.6341 - Test accuracy: 0.7237\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 591ms/step - accuracy: 0.6495 - loss: 0.7510 - val_accuracy: 0.6822 - val_loss: 0.7248\nEpoch 3/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7211 - loss: 0.5911Test loss: 0.6435 - Test accuracy: 0.6946\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 602ms/step - accuracy: 0.7209 - loss: 0.5908 - val_accuracy: 0.6250 - val_loss: 0.8197\nEpoch 4/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7763 - loss: 0.5075Test loss: 0.4727 - Test accuracy: 0.8124\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 583ms/step - accuracy: 0.7759 - loss: 0.5076 - val_accuracy: 0.7140 - val_loss: 0.6916\nEpoch 5/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8078 - loss: 0.4065Test loss: 0.4189 - Test accuracy: 0.8409\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 590ms/step - accuracy: 0.8080 - loss: 0.4055 - val_accuracy: 0.7521 - val_loss: 0.7586\nEpoch 6/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8753 - loss: 0.2843Test loss: 0.5000 - Test accuracy: 0.8359\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 609ms/step - accuracy: 0.8752 - loss: 0.2844 - val_accuracy: 0.7182 - val_loss: 1.1225\nEpoch 7/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8743 - loss: 0.2449Test loss: 0.4877 - Test accuracy: 0.8891\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 584ms/step - accuracy: 0.8748 - loss: 0.2447 - val_accuracy: 0.7500 - val_loss: 1.2673\nEpoch 8/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9150 - loss: 0.1697Test loss: 0.4711 - Test accuracy: 0.8650\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 590ms/step - accuracy: 0.9149 - loss: 0.1709 - val_accuracy: 0.7394 - val_loss: 1.1271\nEpoch 9/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9142 - loss: 0.2005Test loss: 0.3926 - Test accuracy: 0.9037\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 594ms/step - accuracy: 0.9144 - loss: 0.2005 - val_accuracy: 0.7352 - val_loss: 1.0911\nEpoch 10/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9605 - loss: 0.1116Test loss: 0.4749 - Test accuracy: 0.9125\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 588ms/step - accuracy: 0.9605 - loss: 0.1118 - val_accuracy: 0.7415 - val_loss: 1.4771\nEpoch 11/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9759 - loss: 0.0603Test loss: 0.5913 - Test accuracy: 0.9125\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 607ms/step - accuracy: 0.9759 - loss: 0.0606 - val_accuracy: 0.7415 - val_loss: 1.8654\nEpoch 12/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9846 - loss: 0.0352Test loss: 0.5458 - Test accuracy: 0.9227\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 610ms/step - accuracy: 0.9844 - loss: 0.0354 - val_accuracy: 0.7606 - val_loss: 1.7693\nEpoch 13/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9930 - loss: 0.0172Test loss: 0.7197 - Test accuracy: 0.9119\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 584ms/step - accuracy: 0.9929 - loss: 0.0176 - val_accuracy: 0.7309 - val_loss: 2.3152\nEpoch 14/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9864 - loss: 0.0208Test loss: 0.6886 - Test accuracy: 0.9163\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 609ms/step - accuracy: 0.9865 - loss: 0.0210 - val_accuracy: 0.7500 - val_loss: 2.1977\nEpoch 15/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9901 - loss: 0.0294Test loss: 0.7104 - Test accuracy: 0.9138\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 625ms/step - accuracy: 0.9897 - loss: 0.0302 - val_accuracy: 0.7415 - val_loss: 2.2798\nEpoch 16/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9799 - loss: 0.0899Test loss: 0.5921 - Test accuracy: 0.9087\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 619ms/step - accuracy: 0.9795 - loss: 0.0907 - val_accuracy: 0.7415 - val_loss: 1.8144\nEpoch 17/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9756 - loss: 0.0857Test loss: 0.5701 - Test accuracy: 0.9195\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 598ms/step - accuracy: 0.9761 - loss: 0.0838 - val_accuracy: 0.7458 - val_loss: 1.8492\nEpoch 18/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9940 - loss: 0.0168Test loss: 0.5796 - Test accuracy: 0.9221\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 592ms/step - accuracy: 0.9939 - loss: 0.0172 - val_accuracy: 0.7542 - val_loss: 1.8882\nEpoch 19/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9983 - loss: 0.0100Test loss: 0.7554 - Test accuracy: 0.9189\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 612ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 0.7415 - val_loss: 2.4691\nEpoch 20/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9976 - loss: 0.0090Test loss: 0.6679 - Test accuracy: 0.9259\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 589ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.7606 - val_loss: 2.2025\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - accuracy: 0.9087 - loss: 0.7517\nFinal Test Loss: 0.6678791642189026\nFinal Test Accuracy: 92.59%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# 5 Block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 3\nepochs = 20\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Create lists to hold the test loss and accuracy\ntest_loss = []\ntest_accuracy = []\n\n# Custom callback to record test loss and accuracy after each epoch\nclass TestCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        loss, acc = model.evaluate(test_generator, verbose=0)\n        test_loss.append(loss)\n        test_accuracy.append(acc)\n        print(f'Test loss: {loss:.4f} - Test accuracy: {acc:.4f}')\n\n# Train the model with the custom callback\nhistory = model.fit(train_generator_balanced, \n                    epochs=epochs, \n                    validation_data=validation_generator_balanced, \n                    class_weight=class_weights_balanced,\n                    callbacks=[TestCallback()])\n\n# Final evaluation on the test set\nloss, accuracy = model.evaluate(test_generator)\nprint('Final Test Loss:', loss)\nprint(f'Final Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:35:26.969287Z","iopub.execute_input":"2024-11-11T03:35:26.969749Z","iopub.status.idle":"2024-11-11T03:43:10.419020Z","shell.execute_reply.started":"2024-11-11T03:35:26.969700Z","shell.execute_reply":"2024-11-11T03:43:10.418099Z"}},"outputs":[{"name":"stdout","text":"Found 1106 images belonging to 3 classes.\nFound 472 images belonging to 3 classes.\nFound 1578 images belonging to 3 classes.\nEpoch 1/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.4364 - loss: 1.0170Test loss: 0.8530 - Test accuracy: 0.6248\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 734ms/step - accuracy: 0.4368 - loss: 1.0162 - val_accuracy: 0.6144 - val_loss: 0.8565\nEpoch 2/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6366 - loss: 0.8395Test loss: 0.7335 - Test accuracy: 0.6781\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 617ms/step - accuracy: 0.6361 - loss: 0.8387 - val_accuracy: 0.6547 - val_loss: 0.7546\nEpoch 3/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.6194 - loss: 0.7212Test loss: 0.6998 - Test accuracy: 0.6426\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 601ms/step - accuracy: 0.6203 - loss: 0.7195 - val_accuracy: 0.6292 - val_loss: 0.7522\nEpoch 4/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7167 - loss: 0.6120Test loss: 0.7925 - Test accuracy: 0.5938\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 599ms/step - accuracy: 0.7159 - loss: 0.6147 - val_accuracy: 0.5403 - val_loss: 0.8488\nEpoch 5/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.6750 - loss: 0.5939Test loss: 0.5920 - Test accuracy: 0.7186\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 597ms/step - accuracy: 0.6766 - loss: 0.5923 - val_accuracy: 0.6568 - val_loss: 0.7283\nEpoch 6/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7603 - loss: 0.5043Test loss: 0.5649 - Test accuracy: 0.7826\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 586ms/step - accuracy: 0.7595 - loss: 0.5049 - val_accuracy: 0.7161 - val_loss: 0.6872\nEpoch 7/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8137 - loss: 0.4464Test loss: 0.5085 - Test accuracy: 0.7978\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 611ms/step - accuracy: 0.8126 - loss: 0.4455 - val_accuracy: 0.7373 - val_loss: 0.7498\nEpoch 8/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8268 - loss: 0.3496Test loss: 0.4441 - Test accuracy: 0.8409\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 606ms/step - accuracy: 0.8268 - loss: 0.3499 - val_accuracy: 0.7500 - val_loss: 0.7300\nEpoch 9/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8586 - loss: 0.3160Test loss: 0.4978 - Test accuracy: 0.8175\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 608ms/step - accuracy: 0.8579 - loss: 0.3173 - val_accuracy: 0.7288 - val_loss: 0.8327\nEpoch 10/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8954 - loss: 0.2516Test loss: 0.4646 - Test accuracy: 0.8707\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 601ms/step - accuracy: 0.8957 - loss: 0.2518 - val_accuracy: 0.7585 - val_loss: 0.9756\nEpoch 11/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9189 - loss: 0.1846Test loss: 0.5110 - Test accuracy: 0.8878\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 601ms/step - accuracy: 0.9189 - loss: 0.1845 - val_accuracy: 0.7733 - val_loss: 1.3641\nEpoch 12/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9358 - loss: 0.1290Test loss: 0.4744 - Test accuracy: 0.9081\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 597ms/step - accuracy: 0.9361 - loss: 0.1290 - val_accuracy: 0.7669 - val_loss: 1.3774\nEpoch 13/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9534 - loss: 0.1121Test loss: 0.5762 - Test accuracy: 0.9157\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 603ms/step - accuracy: 0.9520 - loss: 0.1139 - val_accuracy: 0.7839 - val_loss: 1.6909\nEpoch 14/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9658 - loss: 0.1106Test loss: 0.4618 - Test accuracy: 0.9233\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 596ms/step - accuracy: 0.9656 - loss: 0.1105 - val_accuracy: 0.7818 - val_loss: 1.4139\nEpoch 15/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9637 - loss: 0.0723Test loss: 0.4883 - Test accuracy: 0.9284\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 606ms/step - accuracy: 0.9638 - loss: 0.0721 - val_accuracy: 0.7903 - val_loss: 1.5295\nEpoch 16/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9598 - loss: 0.0935Test loss: 0.5457 - Test accuracy: 0.9132\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 603ms/step - accuracy: 0.9595 - loss: 0.0943 - val_accuracy: 0.7733 - val_loss: 1.6032\nEpoch 17/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9716 - loss: 0.0865Test loss: 0.6327 - Test accuracy: 0.9189\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 606ms/step - accuracy: 0.9714 - loss: 0.0866 - val_accuracy: 0.7691 - val_loss: 1.9078\nEpoch 18/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9704 - loss: 0.0973Test loss: 0.5790 - Test accuracy: 0.9011\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 602ms/step - accuracy: 0.9697 - loss: 0.0994 - val_accuracy: 0.7712 - val_loss: 1.5922\nEpoch 19/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9513 - loss: 0.1286Test loss: 0.5689 - Test accuracy: 0.9037\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 591ms/step - accuracy: 0.9515 - loss: 0.1274 - val_accuracy: 0.7542 - val_loss: 1.6371\nEpoch 20/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9753 - loss: 0.0683Test loss: 0.4975 - Test accuracy: 0.9240\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 587ms/step - accuracy: 0.9752 - loss: 0.0682 - val_accuracy: 0.7754 - val_loss: 1.5740\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - accuracy: 0.8985 - loss: 0.5527\nFinal Test Loss: 0.49745240807533264\nFinal Test Accuracy: 92.40%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# 6 Block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 3\nepochs = 20\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Create lists to hold the test loss and accuracy\ntest_loss = []\ntest_accuracy = []\n\n# Custom callback to record test loss and accuracy after each epoch\nclass TestCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        loss, acc = model.evaluate(test_generator, verbose=0)\n        test_loss.append(loss)\n        test_accuracy.append(acc)\n        print(f'Test loss: {loss:.4f} - Test accuracy: {acc:.4f}')\n\n# Train the model with the custom callback\nhistory = model.fit(train_generator_balanced, \n                    epochs=epochs, \n                    validation_data=validation_generator_balanced, \n                    class_weight=class_weights_balanced,\n                    callbacks=[TestCallback()])\n\n# Final evaluation on the test set\nloss, accuracy = model.evaluate(test_generator)\nprint('Final Test Loss:', loss)\nprint(f'Final Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:43:10.420491Z","iopub.execute_input":"2024-11-11T03:43:10.421124Z","iopub.status.idle":"2024-11-11T03:50:51.544069Z","shell.execute_reply.started":"2024-11-11T03:43:10.421075Z","shell.execute_reply":"2024-11-11T03:50:51.543128Z"}},"outputs":[{"name":"stdout","text":"Found 1106 images belonging to 3 classes.\nFound 472 images belonging to 3 classes.\nFound 1578 images belonging to 3 classes.\nEpoch 1/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.4458 - loss: 1.0129Test loss: 0.8339 - Test accuracy: 0.6033\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 709ms/step - accuracy: 0.4473 - loss: 1.0115 - val_accuracy: 0.5953 - val_loss: 0.8356\nEpoch 2/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6017 - loss: 0.8656Test loss: 0.6913 - Test accuracy: 0.6705\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 590ms/step - accuracy: 0.6016 - loss: 0.8630 - val_accuracy: 0.6589 - val_loss: 0.7399\nEpoch 3/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6698 - loss: 0.6551Test loss: 0.6823 - Test accuracy: 0.6698\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 594ms/step - accuracy: 0.6684 - loss: 0.6556 - val_accuracy: 0.6610 - val_loss: 0.7541\nEpoch 4/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7194 - loss: 0.6097Test loss: 0.6353 - Test accuracy: 0.6946\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 594ms/step - accuracy: 0.7189 - loss: 0.6093 - val_accuracy: 0.6525 - val_loss: 0.7516\nEpoch 5/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.7504 - loss: 0.5300Test loss: 0.5747 - Test accuracy: 0.7269\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 630ms/step - accuracy: 0.7494 - loss: 0.5302 - val_accuracy: 0.6758 - val_loss: 0.7566\nEpoch 6/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7482 - loss: 0.4908Test loss: 0.5780 - Test accuracy: 0.7452\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 594ms/step - accuracy: 0.7484 - loss: 0.4909 - val_accuracy: 0.6780 - val_loss: 0.8268\nEpoch 7/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7768 - loss: 0.4604Test loss: 0.7156 - Test accuracy: 0.6286\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 588ms/step - accuracy: 0.7753 - loss: 0.4637 - val_accuracy: 0.5403 - val_loss: 0.8472\nEpoch 8/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7538 - loss: 0.5044Test loss: 0.6442 - Test accuracy: 0.7155\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 596ms/step - accuracy: 0.7552 - loss: 0.5018 - val_accuracy: 0.6335 - val_loss: 0.9083\nEpoch 9/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8060 - loss: 0.3837Test loss: 0.5465 - Test accuracy: 0.7997\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 612ms/step - accuracy: 0.8069 - loss: 0.3830 - val_accuracy: 0.6928 - val_loss: 1.0003\nEpoch 10/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8616 - loss: 0.3257Test loss: 0.6673 - Test accuracy: 0.7978\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 600ms/step - accuracy: 0.8608 - loss: 0.3271 - val_accuracy: 0.7097 - val_loss: 1.3066\nEpoch 11/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8430 - loss: 0.3143Test loss: 0.4994 - Test accuracy: 0.8447\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 593ms/step - accuracy: 0.8431 - loss: 0.3149 - val_accuracy: 0.7436 - val_loss: 1.0214\nEpoch 12/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8602 - loss: 0.2663Test loss: 0.4365 - Test accuracy: 0.8555\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 595ms/step - accuracy: 0.8604 - loss: 0.2661 - val_accuracy: 0.7585 - val_loss: 0.9273\nEpoch 13/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9009 - loss: 0.1987Test loss: 0.5670 - Test accuracy: 0.7978\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 597ms/step - accuracy: 0.9000 - loss: 0.2009 - val_accuracy: 0.7267 - val_loss: 1.0032\nEpoch 14/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8800 - loss: 0.2457Test loss: 0.6235 - Test accuracy: 0.8435\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 590ms/step - accuracy: 0.8797 - loss: 0.2458 - val_accuracy: 0.7182 - val_loss: 1.4365\nEpoch 15/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8835 - loss: 0.2682Test loss: 0.4719 - Test accuracy: 0.8701\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 580ms/step - accuracy: 0.8841 - loss: 0.2664 - val_accuracy: 0.7479 - val_loss: 1.0351\nEpoch 16/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9158 - loss: 0.1847Test loss: 0.5240 - Test accuracy: 0.8574\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 601ms/step - accuracy: 0.9153 - loss: 0.1873 - val_accuracy: 0.7373 - val_loss: 1.2305\nEpoch 17/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8875 - loss: 0.2512Test loss: 0.3472 - Test accuracy: 0.8828\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 590ms/step - accuracy: 0.8876 - loss: 0.2528 - val_accuracy: 0.7627 - val_loss: 0.7187\nEpoch 18/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9350 - loss: 0.1341Test loss: 0.4593 - Test accuracy: 0.9049\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 593ms/step - accuracy: 0.9353 - loss: 0.1335 - val_accuracy: 0.7797 - val_loss: 1.2787\nEpoch 19/20\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9625 - loss: 0.0855Test loss: 0.5021 - Test accuracy: 0.9056\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 650ms/step - accuracy: 0.9625 - loss: 0.0854 - val_accuracy: 0.7797 - val_loss: 1.4015\nEpoch 20/20\n\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9424 - loss: 0.1205Test loss: 0.4596 - Test accuracy: 0.9170\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 581ms/step - accuracy: 0.9430 - loss: 0.1195 - val_accuracy: 0.7775 - val_loss: 1.3631\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.9126 - loss: 0.3857\nFinal Test Loss: 0.4595556855201721\nFinal Test Accuracy: 91.70%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# 7 Block","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 3\nepochs = 20\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Create lists to hold the test loss and accuracy\ntest_loss = []\ntest_accuracy = []\n\n# Custom callback to record test loss and accuracy after each epoch\nclass TestCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        loss, acc = model.evaluate(test_generator, verbose=0)\n        test_loss.append(loss)\n        test_accuracy.append(acc)\n        print(f'Test loss: {loss:.4f} - Test accuracy: {acc:.4f}')\n\n# Train the model with the custom callback\nhistory = model.fit(train_generator_balanced, \n                    epochs=epochs, \n                    validation_data=validation_generator_balanced, \n                    class_weight=class_weights_balanced,\n                    callbacks=[TestCallback()])\n\n# Final evaluation on the test set\nloss, accuracy = model.evaluate(test_generator)\nprint('Final Test Loss:', loss)\nprint(f'Final Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:50:51.545535Z","iopub.execute_input":"2024-11-11T03:50:51.546279Z","iopub.status.idle":"2024-11-11T03:50:52.105406Z","shell.execute_reply.started":"2024-11-11T03:50:51.546241Z","shell.execute_reply":"2024-11-11T03:50:52.103922Z"}},"outputs":[{"name":"stdout","text":"Found 1106 images belonging to 3 classes.\nFound 472 images belonging to 3 classes.\nFound 1578 images belonging to 3 classes.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m---> 70\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m     73\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/sequential.py:120\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:223\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m--> 223\u001b[0m         \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/sequential.py:183\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/ops/operation_utils.py:221\u001b[0m, in \u001b[0;36mcompute_conv_output_shape\u001b[0;34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed output size would be negative. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`inputs shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`kernel shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dilation_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilation_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m             )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    228\u001b[0m     output_spatial_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor((spatial_shape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m strides) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mValueError\u001b[0m: Computed output size would be negative. Received `inputs shape=(None, 1, 1, 128)`, `kernel shape=(3, 3, 128, 128)`, `dilation_rate=[1 1]`."],"ename":"ValueError","evalue":"Computed output size would be negative. Received `inputs shape=(None, 1, 1, 128)`, `kernel shape=(3, 3, 128, 128)`, `dilation_rate=[1 1]`.","output_type":"error"}],"execution_count":8}]}